{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing main modules\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the dataset\n",
    "df = pd.read_csv(\"Crop_recommendation.csv\")\n",
    "# print(df.head())\n",
    "\n",
    "# #checking the shape of the dataset\n",
    "# print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #overview of dataset columns\n",
    "# df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #num of values/observations for each class\n",
    "# df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #checking for duplicate values\n",
    "# df.loc[df.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #checking for null values\n",
    "# df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #checking outliers\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# sns.boxplot(data=df)\n",
    "# plt.title('Box Plot of Features')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # checking distribution for each feature\n",
    "# for column in df.columns:\n",
    "#     plt.figure(figsize=(5, 3))\n",
    "#     sns.histplot(df[column], bins=100)\n",
    "#     plt.title(f'Distribution of {column}')\n",
    "#     plt.show()\n",
    "\n",
    "# Ideal transformations for features :\n",
    "# N: Robust Scaler\n",
    "# P' : Robust Scaler\n",
    "# K: Robust Scaler\n",
    "# Temp, ph: Standard Scaler\n",
    "# Humidity, Rainfall: Log transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for column in df1.columns:\n",
    "#     plt.figure(figsize=(5, 3))\n",
    "#     sns.kdeplot(df[column])\n",
    "#     plt.title(f'Distribution of {column}')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for column in df.columns:\n",
    "#     plt.figure(figsize=(10,6))\n",
    "#     sns.scatterplot(data=df, x=column, y='label', hue='label')\n",
    "#     plt.title(f'Distribution of {column}')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #checking relations for features with each other\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# sns.pairplot(df, hue='label')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #checking correlation\n",
    "# df1= df.drop('label', axis=1)\n",
    "# corr = df1.corr()\n",
    "# plt.figure(figsize=(12, 8))\n",
    "# sns.heatmap(corr, annot=True, cmap='coolwarm')\n",
    "# plt.title('Correlation Matrix')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.columns.unique()\n",
    "\n",
    "# le = LabelEncoder()\n",
    "# df['label']= le.fit_transform(df['label']) \n",
    "# df['label'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #checking correlation\n",
    "# corr = df.corr()\n",
    "# plt.figure(figsize=(12, 8))\n",
    "# sns.heatmap(corr, annot=True, cmap='coolwarm')\n",
    "# plt.title('Correlation Matrix')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['rain-ph'] = df['rainfall'] - df['ph']\n",
    "# df.head()\n",
    "# corr = df.corr()\n",
    "# plt.figure(figsize=(12, 8))\n",
    "# sns.heatmap(corr, annot=True, cmap='coolwarm')\n",
    "# plt.title('Correlation Matrix')\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\bhanu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.5.0)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\bhanu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\bhanu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.14.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\bhanu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\bhanu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (3.5.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: C:\\Users\\bhanu\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# le = LabelEncoder()\n",
    "# df['label']= le.fit_transform(df['label']) \n",
    "# df['label'].unique()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['label'] = df['label'].map({\n",
    "# 'rice' : 0,          \n",
    "# 'maize' : 1,        \n",
    "# 'jute' : 2,          \n",
    "# 'cotton' : 3,      \n",
    "# 'coconut' : 4,       \n",
    "# 'papaya' : 5,        \n",
    "# 'orange' : 6,        \n",
    "# 'apple'  : 7,         \n",
    "# 'muskmelon' : 8,    \n",
    "# 'watermelon'  : 9,   \n",
    "# 'grapes' : 10,       \n",
    "# 'mango'  :11,       \n",
    "# 'banana'  : 12,      \n",
    "# 'pomegranate'  : 13, \n",
    "# 'lentil'   :14,     \n",
    "# 'blackgram' : 15,    \n",
    "# 'mungbean'  : 16,    \n",
    "# 'mothbeans'  : 17,   \n",
    "# 'pigeonpeas'  : 18,  \n",
    "# 'kidneybeans'  : 19, \n",
    "# 'chickpea' : 20,   \n",
    "# 'coffee' : 21      \n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data, such that 20% from each class goes into \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = df.drop(columns=['label'])\n",
    "y = df['label']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, stratify=y, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in x_train.columns:\n",
    "#     plt.figure(figsize=(10, 5))\n",
    "    \n",
    "#     plt.subplot(1, 2, 1)\n",
    "#     sns.histplot(x_train[col], kde=True)\n",
    "#     plt.title(f'{col} Distribution in Training Set')\n",
    "    \n",
    "#     plt.subplot(1, 2, 2)\n",
    "#     sns.histplot(x_test[col], kde=True)\n",
    "#     plt.title(f'{col} Distribution in Test Set')\n",
    "    \n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, OneHotEncoder\n",
    "# from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "NPK_cols = ['N','P', 'K']\n",
    "temp_ph_cols = ['temperature', 'ph']\n",
    "rainfall_humidity_cols = ['rainfall', 'humidity']\n",
    "\n",
    "transformed_columns = ['N', 'P', 'K', 'temperature', 'ph', 'rainfall', 'humidity']\n",
    "\n",
    "# x_train_transformed_df1 = pd.DataFrame(x_train_combined, columns=transformed_columns)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Apply RobustScaler to N, P, K\n",
    "robust_scaler = RobustScaler()\n",
    "\n",
    "\n",
    "x_train_NPK = robust_scaler.fit_transform(x_train[NPK_cols])\n",
    "x_test_NPK = robust_scaler.transform(x_test[NPK_cols])\n",
    "\n",
    "# Create new DataFrames from the transformed arrays\n",
    "x_train[NPK_cols] = pd.DataFrame(x_train_NPK, columns=NPK_cols, index=x_train.index)\n",
    "x_test[NPK_cols] = pd.DataFrame(x_test_NPK, columns=NPK_cols, index=x_test.index)\n",
    "\n",
    "# Apply StandardScaler to temperature and ph\n",
    "standard_scaler_temp_ph = StandardScaler()\n",
    "x_train_temp_ph = standard_scaler_temp_ph.fit_transform(x_train[temp_ph_cols])\n",
    "x_test_temp_ph = standard_scaler_temp_ph.transform(x_test[temp_ph_cols])\n",
    "\n",
    "# Create new DataFrames from the transformed arrays\n",
    "x_train[temp_ph_cols] = pd.DataFrame(x_train_temp_ph, columns=temp_ph_cols, index=x_train.index)\n",
    "x_test[temp_ph_cols] = pd.DataFrame(x_test_temp_ph, columns=temp_ph_cols, index=x_test.index)\n",
    "\n",
    "# Apply log transformation to rainfall and humidity\n",
    "x_train[rainfall_humidity_cols] = np.log1p(x_train[rainfall_humidity_cols])\n",
    "x_test[rainfall_humidity_cols] = np.log1p(x_test[rainfall_humidity_cols])\n",
    "\n",
    "# Combine the transformed features back into single datasets\n",
    "x_train_combined = x_train[NPK_cols + temp_ph_cols + rainfall_humidity_cols]\n",
    "x_test_combined = x_test[NPK_cols + temp_ph_cols + rainfall_humidity_cols]\n",
    "\n",
    "\n",
    "# Apply a final StandardScaler to the combined datasets\n",
    "final_scaler = StandardScaler()\n",
    "x_train_transformed = final_scaler.fit_transform(x_train_combined)\n",
    "x_test_transformed = final_scaler.transform(x_test_combined)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformed_columns = ['N', 'P', 'K', 'temperature', 'ph', 'rainfall', 'humidity']\n",
    "\n",
    "# x_train_transformed_df = pd.DataFrame(x_train_transformed, columns=transformed_columns)\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "    \n",
    "# plt.subplot(1, 2, 1)\n",
    "# sns.histplot(x_train['N'], kde=True)\n",
    "# plt.title(' Distribution in Training Set')\n",
    "    \n",
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "    \n",
    "# plt.subplot(1, 2, 1)\n",
    "# sns.histplot(x_train['P'], kde=True)\n",
    "# plt.title(' Distribution in Training Set')\n",
    "    \n",
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "    \n",
    "# plt.subplot(1, 2, 1)\n",
    "# sns.histplot(x_train['K'], kde=True)\n",
    "# plt.title(' Distribution in Training Set')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformed_columns = ['N', 'P', 'K', 'temperature', 'ph', 'rainfall', 'humidity']\n",
    "\n",
    "# x_train_transformed_df = pd.DataFrame(x_train_transformed, columns=transformed_columns)\n",
    "\n",
    "# for col in x_train.columns:\n",
    "#     plt.figure(figsize=(10, 5))\n",
    "    \n",
    "#     plt.subplot(1, 2, 1)\n",
    "#     sns.histplot(x_train[col], kde=True)\n",
    "#     plt.title(f'{col} Distribution in Training Set')\n",
    "    \n",
    "#     plt.subplot(1, 2, 2)\n",
    "#     sns.histplot(x_train_transformed_df[col], kde=True)\n",
    "#     plt.title(f'{col} Distribution in Test Set')\n",
    "    \n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "x_train_poly = poly.fit_transform(x_train_transformed)\n",
    "x_test_poly = poly.transform(x_test_transformed)\n",
    "\n",
    "feature_names = poly.get_feature_names_out(['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall'])\n",
    "\n",
    "x_train_poly_df = pd.DataFrame(x_train_poly, columns= feature_names)\n",
    "x_test_poly_df = pd.DataFrame(x_test_poly, columns= feature_names)\n",
    "\n",
    "feature_names_in_ =  x_train_poly_df.columns.unique()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['P', 'ph', 'rainfall', 'K rainfall', 'ph rainfall'], dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFECV, RFE\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "estimator = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "selector = RFE(estimator, n_features_to_select = 5  , step=1)\n",
    "\n",
    "selector = selector.fit(x_train_poly, y_train)\n",
    "\n",
    "selector.get_feature_names_out(feature_names_in_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9517045454545454\n",
      "Classwise averaged score: 0.9517045454545454\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, balanced_accuracy_score\n",
    "\n",
    "x_train1, x_val, y_train1, y_val = train_test_split(x_train_poly, y_train, test_size=0.2, stratify=y_train, random_state=42)\n",
    "\n",
    "# Initialize the k-NN model\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "\n",
    "# Train the model on the training data\n",
    "knn.fit(x_train1, y_train1)\n",
    "\n",
    "\n",
    "# Predict on the test data using the best k\n",
    "y_pred1 = knn.predict(x_val)\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_val, y_pred1)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "quality_criteria = balanced_accuracy_score(y_val, y_pred1)\n",
    "print(f\"Classwise averaged score: {quality_criteria}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9522727272727273\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, balanced_accuracy_score\n",
    "\n",
    "# Initialize the k-NN model\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "final_col = ['P', 'ph', 'rainfall', 'K rainfall', 'ph rainfall']\n",
    "\n",
    "x_train_final = x_train_poly_df[final_col]\n",
    "x_test_final = x_test_poly_df[final_col]\n",
    "\n",
    "\n",
    "x_train_final.head()\n",
    "\n",
    "\n",
    "# Train the model on the training data\n",
    "knn.fit(x_train_final, y_train)\n",
    "\n",
    "\n",
    "# Predict on the test data using the best k\n",
    "y_pred = knn.predict(x_test_final)\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Quality criterai\n",
    "2. Feature selection(3 algo)\n",
    "3. Dimentionality reduction\n",
    "4. Model Short listing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
